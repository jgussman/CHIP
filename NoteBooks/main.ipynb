{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                       References\n",
    "[HIRES PRV Documentation](https://caltech-ipac.github.io/hiresprv/hiresprv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                     Imports & Setup\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from hiresprv.auth import login\n",
    "from hiresprv.idldriver import Idldriver\n",
    "from hiresprv.database import Database\n",
    "from hiresprv.download import Download\n",
    "from PyAstronomy import pyasl\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.spectra import Spectrum1D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOA userid: jgussman\n",
      "KOA Password: ········\n",
      "Successful login as jgussman\n"
     ]
    }
   ],
   "source": [
    "login('prv.cookies')                 # For logging into the NExSci servers \n",
    "\n",
    "idl = Idldriver('prv.cookies')       # For creating RV scripts \n",
    "\n",
    "state = Database('prv.cookies')      # For retrieving data from HIRES \n",
    "\n",
    "data = Download('prv.cookies', './RVOutput') # For downloading spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                         Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starnames_crossmatch_SPOCS_NEXSCI.txt was put together by Malena Rice \n",
    "# This matches SPOC stars with their HIRES ID \n",
    "crossMatchedNames = pd.read_csv(\"../spocData/starnames_crossmatch_SPOCS_NEXSCI.txt\",sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        RV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the RV data for each star\n",
    "#1) Find all the RV observations \n",
    "def Find_and_download_all_rv_obs(star_ID_List,idldriver,database):\n",
    "    '''    \n",
    "    INPUT: star_ID_List is a list that contains strings of the HIRES ID for stars \n",
    "           idldriver needs be a hiresprv.idldriver.Idldriver instance \n",
    "           database needs to be hiresprv.database.Database instance \n",
    "    OUTPUT: {keys = HIRES filename: value = RV Data}\n",
    "    \n",
    "    Description: This function downloads the rotational velocity metadata and\n",
    "    returns a dictionary that makes it easy to identify what stars' max observed \n",
    "    rotational velocities as well as the filenames for which they came from.\n",
    "     \n",
    "    '''\n",
    "    rv_script_name_list = []\n",
    "    problem_child_name = []\n",
    "    problem_child_rv = []\n",
    "    problem_child_filename = []\n",
    "    master_script = \"\"\n",
    "    for HIRESname in star_ID_List:\n",
    "        try:\n",
    "                #Create script for reducing RV observations\n",
    "                temp_rv_script = idldriver.create_rvscript(HIRESname,database) \n",
    "\n",
    "                length_of_name = len(HIRESname)\n",
    "                first_date = temp_rv_script[3+length_of_name:13+length_of_name].split(\".\")[0]\n",
    "\n",
    "                HIRESrvname = temp_rv_script[3:length_of_name+3].split(\" \")[0]\n",
    "\n",
    "                temp_rv_script =  \"template {0} {1}\\n\".format(HIRESrvname,first_date) + temp_rv_script\n",
    "                temp_rv_script += \"\\nrvcurve {0}\\n\".format(HIRESrvname)\n",
    "                rv_script_name_list.append(HIRESrvname)\n",
    "                master_script += temp_rv_script\n",
    "\n",
    "        except AttributeError: #This is due to the idldriver.create_rvscript \n",
    "            problem_child_name = [HIRESname] + problem_child_name\n",
    "            problem_child_rv += [pd.NA]\n",
    "            problem_child_filename += [pd.NA]\n",
    "        \n",
    "    #Run script \n",
    "    idldriver.run_script(master_script) \n",
    "    \n",
    "    #Downloading the RV data as well as getting the largest RV value for each star\n",
    "    largest_rv = {\"HIRESName\": problem_child_name,\"FILENAME\":problem_child_filename, \"RV\":problem_child_rv}  \n",
    "    localdir = data.localdir\n",
    "    for name in rv_script_name_list:\n",
    "        #Make sure the data is in workspace\n",
    "        largest_rv[\"HIRESName\"].append(name)\n",
    "        try:\n",
    "            rtn = data.rvcurve(name)\n",
    "            nameLoc = '{0}/vst{1}.csv'.format(localdir,name)\n",
    "            temp_df = pd.read_csv(nameLoc)\n",
    "            if not temp_df.empty:\n",
    "                rv_temp = abs(temp_df['RV'])\n",
    "                row = temp_df[temp_df['RV'] == rv_temp.min()]\n",
    "                if row.empty: #The absolute max rv is negative \n",
    "                    row = temp_df[temp_df['RV'] == -rv_temp.min()]\n",
    "                largest_rv[\"RV\"] += [row[\"RV\"].to_numpy()[0]]\n",
    "                largest_rv[\"FILENAME\"] += [row[\"FILENAME\"].to_numpy()[0]]\n",
    "            else:\n",
    "                largest_rv[\"RV\"] += [pd.NA]\n",
    "                largest_rv[\"FILENAME\"] += [pd.NA]\n",
    "        except OSError: #This error occurs because for some reason the star's rvcurve wasn't created\n",
    "                largest_rv[\"RV\"] += [pd.NA]\n",
    "                largest_rv[\"FILENAME\"] += [pd.NA]\n",
    "    return largest_rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                       Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retreive all the Spectra \n",
    "def DownloadSpectra(filename_rv_df,download):\n",
    "    '''\n",
    "    Input: filename_rv_df dataframe with a column called \"FILENAME\" that contains the HIRES \n",
    "                          filename you want to download the deblazed spectra of. \n",
    "           download needs to be a hiresprv.download.Download instance \n",
    "   \n",
    "    Output: {HIRES FILENAME: 1-D spectra array}\n",
    "    \n",
    "    Description: THIS FUNCTION ASSUMES YOU DID .dropna() ON filename_rv_df\n",
    "    This function downloads all the \n",
    "    '''\n",
    "    \n",
    "    spectraDic = {} \n",
    "    download_Location = download.localdir #This is the second parameter of hiresprv.download.Download\n",
    "    for filename in filename_rv_df[\"FILENAME\"]:\n",
    "        #I tried to use the , seperation and new line seperation \n",
    "        #for the different file names but it doesn't seem to work.\n",
    "        #Thus, a for-loop was used!\n",
    "        download.spectrum(filename.replace(\"r\",\"\"))  #Download spectra \n",
    "        \n",
    "        temp_deblazedFlux = fits.getdata(\"{0}/{1}.fits\".format(download_Location,filename))\n",
    "        spectraDic[filename] = np.append(temp_deblazedFlux[0],[temp_deblazedFlux[i] for i in range(1,16)])     \n",
    "    \n",
    "    return spectraDic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ContinuumNormalize(spectraDic,download):\n",
    "    '''\n",
    "    Input: spectraDic is {HIRES FILENAME: 1-D spectra array}\n",
    "           download needs to be a hiresprv.download.Download instance \n",
    "           \n",
    "    Output: {HIRES FILENAME: 1-D continumm Normalized spectra}\n",
    "    \n",
    "    Description: This function uses specutils' Spectrum1D function to determine the \n",
    "    continum of spectra. \n",
    "    '''\n",
    "    #This is the same for all HIRES data \n",
    "    wl_solution = fits.getdata('http://caltech-ipac.github.io/hiresprv/_static/keck_rwav.fits')\n",
    "    wl_solution = np.append(wl_solution[0],[wl_solution[i] for i in range(1,16)]) #UNITS: Angstrom\n",
    "    wl_solution_micrometer = wl_solution*0.0001 #UNITS: µm\n",
    "    spectral_axis_wl_solution = wl_solution*u.um\n",
    "    photonEnergy = 1.2398 / wl_solution_micrometer #h*c/lambda = 1.2398 eV-µm/lambda \n",
    "    \n",
    "    \n",
    "    download_Location = download.localdir \n",
    "    #Continumm Normalize\n",
    "    for filename in spectraDic:\n",
    "        deblazedFlux = spectraDic[filename]\n",
    "        hdu = fits.open(\"{0}/{1}.fits\".format(download_Location,filename))\n",
    "        timeElapsed = hdu[0].header[\"ELAPTIME\"]\n",
    "        hdu.close()\n",
    "        photonsPersec = deblazedFlux/timeElapsed\n",
    "    \n",
    "        ergsPerSecFlux = photonEnergy*photonsPersec*u.Jy\n",
    "        \n",
    "        normalized_array = np.array([])\n",
    "        for j in range(0,16): #Normalize each individual echelle order \n",
    "            i  = 4021 * j\n",
    "            temp_echelle_flux = ergsPerSecFlux[i:i+4021]\n",
    "            temp_echelle_wl = spectral_axis_wl_solution[i:i+4021]\n",
    "            spectrum = Spectrum1D(flux=temp_echelle_flux, spectral_axis=temp_echelle_wl )\n",
    "            g1_fit = fit_generic_continuum(spectrum)\n",
    "            flux_fit = g1_fit(temp_echelle_wl)\n",
    "\n",
    "            normalized_echelle = temp_echelle_flux / flux_fit\n",
    "      \n",
    "            #Converting to a float like this removes 2 decimal places from normalized_echelle\n",
    "            normalized_echelle = np.array(list(map(np.float,normalized_echelle)))  \n",
    "            \n",
    "            normalized_array = np.append(normalized_array,normalized_echelle)\n",
    "            \n",
    "        spectraDic[filename] = normalized_array\n",
    "        \n",
    "    return spectraDic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossCorrelate(filename_rv_df,normalized_Spectra):\n",
    "    '''\n",
    "    Input: filename_rv_df is the same dataframe produced by Find_and_download_all_rv_obs\n",
    "           normalized_Spectra is the output of ContinuumNormalize\n",
    "   \n",
    "    Output:  {HIRES FILENAME: 1-D shifted spectra}\n",
    "    \n",
    "    Description: THIS FUNCTION ASSUMES YOU DID .dropna() ON THE DATAFRAME\n",
    "    Uses Pyastronomy's crosscorrRV function to compute the cross correlation.  \n",
    "    '''\n",
    "    wvnum, wvlen, crf, tel, c, n = np.genfromtxt(\"../Atlases/solarAtlas.txt\",skip_header=1,unpack=True)\n",
    "    wvnum, wvlen, crf, tel, c, n = wvnum[::-1], wvlen[::-1], crf[::-1], tel[::-1], c[::-1], n[::-1] \n",
    "    \n",
    "    wl_solution = fits.getdata('http://caltech-ipac.github.io/hiresprv/_static/keck_rwav.fits')\n",
    "    wl_solution = np.append(wl_solution[0],[wl_solution[i] for i in range(1,16)])\n",
    "    \n",
    "    crossCorrelatedspectra = {} #Key: FILENAME Values: (correlated wavelength, normalized flux)\n",
    "    for i in range(filename_rv_df.shape[0]):\n",
    "        row = filename_rv_df.iloc[i]\n",
    "        filename = row[1]\n",
    "        RV = abs(row[2])\n",
    "        \n",
    "        normalizedFlux = normalized_Spectra[filename]\n",
    "        \n",
    "        rv, cc = pyasl.crosscorrRV(wl_solution, normalizedFlux, wvlen,c, -1*RV, RV, RV/100., skipedge=25)\n",
    "        maxind = np.argmax(cc)\n",
    "        argRV = rv[maxind]  #UNITS: km/s \n",
    "        \n",
    "        # z = v_0/c    \n",
    "        z = (argRV/299_792.458) #UNITS: None \n",
    "        computeShiftedWavelength = lambda wl: wl + wl*z #UNITS: Angstroms \n",
    "        shifted_wl = np.array(list(map(computeShiftedWavelength,wl_solution)))\n",
    "        \n",
    "        #Making the key the HIRES ID so I easily convert it back to the Spoc ID later\n",
    "        crossCorrelatedspectra[row[0]] = (shifted_wl,normalizedFlux) \n",
    "    \n",
    "    return crossCorrelatedspectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interpolate(spectraDic):\n",
    "    '''\n",
    "    Input: spectraDic is the output of the function CrossCorrelate \n",
    "   \n",
    "    Output:  {HIRES ID: 1-D interpolated spectra}, 1-D wavelength array that all the spectra use\n",
    "    \n",
    "    Description: THIS FUNCTION ASSUMES YOU DID .dropna() ON THE DATAFRAME\n",
    "    This function not only returns a {} of the intertpolated spectra but it also, \n",
    "    downloads the interpolated wavelength to interpolated_wl.csv and downloads the\n",
    "    fluxes to fluxes_for_HIRES.csv. \n",
    "    '''\n",
    "    \n",
    "    #Interpolate the spectra with each other to get the same wavelength scale for all of them.\n",
    "    firstKey = next(iter(spectraDic))\n",
    "    first_spectra = spectraDic[firstKey][0]\n",
    "    wl_length = len(first_spectra)\n",
    "    \n",
    "    \n",
    "    maxMinVal = float('-inf')\n",
    "    minMaxVal = float('inf')\n",
    "    #Finds the max minimum wavelength val & finds the min maximum wavelenght val \n",
    "    for spectra_flux_tuple in spectraDic.values(): \n",
    "        #Assumption: wavelength is sorted from the 0th index being min,\n",
    "        #            the len(wavelength array)-1 is the max wavelength val,\n",
    "        #            all the wavelength arrays are the same length.\n",
    "        temp_spectra = spectra_flux_tuple[0]\n",
    "        temp_min_wl = temp_spectra[0]\n",
    "        temp_max_wl = temp_spectra[wl_length-1]\n",
    "        \n",
    "        if maxMinVal < temp_min_wl:\n",
    "            maxMinVal = temp_min_wl\n",
    "        if minMaxVal > temp_max_wl:\n",
    "            minMaxVal = temp_max_wl\n",
    "    \n",
    "    #wavelength range \n",
    "    interpolate_over = [wl for wl in first_spectra if wl >= maxMinVal and wl<=minMaxVal]\n",
    "    \n",
    "    fluxDic = {}\n",
    "    for HIRES_ID in spectraDic:\n",
    "        wl = spectraDic[HIRES_ID][0]\n",
    "        flux_norm = spectraDic[HIRES_ID][1]\n",
    "        interpolated_flux = np.interp(interpolate_over,x,flux_norm)\n",
    "        fluxDic[HIRES_ID] = interpolated_flux\n",
    "    \n",
    "    #Saving \n",
    "    np.savetxt(\"interpolated_wl.csv\",interpolate_over,delimiter=\",\")\n",
    "    fluxDF = pd.DataFrame(fluxDic)\n",
    "    fluxDF.to_csv(\"fluxes_for_HIRES.csv\",index_label=False,index=False)\n",
    "    return fluxDF, interpolate_over\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                       Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status= ok\n",
      "msg= Script running in background. Consult monitor for status.\n"
     ]
    }
   ],
   "source": [
    "#RV\n",
    "rv_start = time.time()\n",
    "name_filename_rv_dic = Find_and_download_all_rv_obs(crossMatchedNames[\"HIRES\"].to_numpy(),idl,state)\n",
    "name_filename_rv_df = pd.DataFrame(name_filename_rv_dic)\n",
    "name_filename_rv_df.to_csv(\"HIRES_Filename_rv.csv\",index_label=False,index=False)\n",
    "rv_time_elap = time.time() - rv_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_time_elap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2a88f1ffb7f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prv.cookies'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./SpectraOutput'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For downloading spectra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mspectraForStars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDownloadSpectra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_filename_rv_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdownload_time_elap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdownload_time_elap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'download_time_elap' is not defined"
     ]
    }
   ],
   "source": [
    "#Download Spectra \n",
    "download_start = time.time()\n",
    "name_filename_rv_df = pd.read_csv(\"HIRES_Filename_rv.csv\").dropna() \n",
    "data = Download('prv.cookies', './SpectraOutput') # For downloading spectra\n",
    "spectraForStars = DownloadSpectra(name_filename_rv_df,data)\n",
    "download_time_elap = time.time() - download_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continum Normalize\n",
    "normalization_start = time.time()\n",
    "normalizedSpectraDic = ContinuumNormalize(spectraForStars,data)\n",
    "normalization_time_elap = time.time() - normalization_start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_start = time.time()\n",
    "crossCorrelatedSpectra = CrossCorrelate(name_filename_rv_df,normalizedSpectraDic)\n",
    "correlated_time_elap = time.time() - correlated_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_start = time.time()\n",
    "flux_df, interpolate_array = Interpolate(crossCorrelatedSpectra)\n",
    "interpolate_time_elap = time.time() - interpolate_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 11.568602812290191 minutes to complete the RV func\n",
      "It took 36.94154184261958 minutes to complete the download spectra func\n",
      "It took 57.14264868895213 minutes to complete the normalization func\n",
      "It took 123.83144724369049 minutes to complete the cross-correlation func\n",
      "It took 1.183903447786967 minutes to complete the interpolate func\n"
     ]
    }
   ],
   "source": [
    "print(f\"It took {rv_time_elap/60} minutes to complete the RV func\")\n",
    "print(f\"It took {download_time_elap/60} minutes to complete the download spectra func\")\n",
    "print(f\"It took {normalization_time_elap/60} minutes to complete the normalization func\")\n",
    "print(f\"It took {correlated_time_elap/60} minutes to complete the cross-correlation func\")\n",
    "print(f\"It took {interpolate_time_elap/60} minutes to complete the interpolate func\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
