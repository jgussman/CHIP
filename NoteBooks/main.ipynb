{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from hiresprv.auth import login\n",
    "from hiresprv.idldriver import Idldriver\n",
    "from hiresprv.database import Database\n",
    "from hiresprv.download import Download\n",
    "from PyAstronomy import pyasl\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.spectra import Spectrum1D\n",
    "from scipy import interpolate \n",
    "from alpha_shapes import * \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "class CIR:\n",
    "\n",
    "    def __init__(self,star_ID_array,wl_solution_path = './wl_solution.csv',\n",
    "                 rvOutputPath='./RVOutput',spectraOutputPath = './SpectraOutput' ):\n",
    "        '''\n",
    "        Used for reducing deblazed Keck HIRES spectra for the purpose of putting the output \n",
    "        inot The Cannon. \n",
    "\n",
    "        star_ID_array: is an array that contains strings of the HIRES ID for stars\n",
    "        wl_solution_path: defaulted to ./wl_solution.csv, the file at the end of your given path\n",
    "                          needs to have the first 2 rows not contain data. skip_header is set to 2\n",
    "        rvOutputPath: defaulted to ./RVOutput, the folder at the end of your path needs to have already\n",
    "                      been created before you initalize this class\n",
    "        spectraOutputPath: defaulted to ./SpectraOutput, the folder at the end of your path needs to have \n",
    "                            already been created before you initalize this class\n",
    "        '''\n",
    "\n",
    "        login('prv.cookies')                                               # For logging into the NExSci servers \n",
    "        self.idldriver = Idldriver('prv.cookies')                          # For creating RV scripts \n",
    "        self.state = Database('prv.cookies')                               # For retrieving data from HIRES \n",
    "        self.dataRV = Download('prv.cookies', rvOutputPath)                # For downloading RV\n",
    "        self.dataSpectra = Download('prv.cookies',spectraOutputPath)       # For downloading Spectra \n",
    "        self.star_ID_array = star_ID_array                                 # HIRES ID \n",
    "        self.wl_solution = np.genfromtxt(wl_solution_path,skip_header=2)   # UNITS: Angstrom\n",
    "        self.Ivar = {}                                                     # For storing sigma valeus \n",
    "        self.filename_rv_df = pd.DataFrame()                               # For storing meta Data\n",
    "        \n",
    "    \n",
    "    def Run(self,use_data=False,slow_normalize = False ):\n",
    "        '''\n",
    "        Description: This method will run all of the following\n",
    "            Unless parameter is set to True\n",
    "             Find_and_download_all_rv_obs -> \n",
    "             DownloadSpectra ->\n",
    "             Continuum Normalize ->\n",
    "             CrossCorrelate -> \n",
    "             Interpolate \n",
    "        \n",
    "        use_data:  Set to True if you have HIRES_Filename_rv.csv \n",
    "                  populated with the stars you want from a previous run. \n",
    "        slow_normalize: Set to True if you have a ton of time or a really fast computer.\n",
    "                        700 stars will take ~48 hours. Plus shipping and handling.\n",
    "        '''\n",
    "        if not use_data:\n",
    "            self.Find_and_download_all_rv_obs()\n",
    "            self.DownloadSpectra()\n",
    "        else:\n",
    "            self.NoDownload()\n",
    "        if not slow_normalize:\n",
    "            self.ContinuumNormalize()\n",
    "        else:\n",
    "            self.AlphaNormalization()\n",
    "        self.CrossCorrelate()\n",
    "        self.Interpolate()\n",
    "\n",
    "\n",
    "    def Find_and_download_all_rv_obs(self):\n",
    "        '''            \n",
    "        Description: This method downloads the rotational velocity metadata and\n",
    "        returns a dictionary that makes it easy to identify what stars' rotational \n",
    "        velocities nearest 0 as well as the filenames for which they came from. \n",
    "\n",
    "        Note: The dataframe produced by this method will remove all the stars that did \n",
    "              not have any RV data produced by rvcurve. This does not mean that \n",
    "              the star doesn't have any RV data. It could mean a few things, the ID\n",
    "              is wrong, contains a character that isn't currently supported by the \n",
    "              HIRES pipeline, it could have too few RV observations to make an \n",
    "              RV curve, etc...\n",
    "        '''\n",
    "        print(\"Downloading RV Data Has Began\")\n",
    "        #Downloading the RV data as well as getting the largest RV value for each star\n",
    "        hiresName_fileName_rv_dic = {\"HIRESName\": [],\"FILENAME\":[], \"RV\":[]}  \n",
    "        rvDownloadLocation = self.dataRV.localdir\n",
    "        for name in self.star_ID_array:\n",
    "            #Make sure the data is in workspace\n",
    "            hiresName_fileName_rv_dic[\"HIRESName\"].append(name)\n",
    "            try:\n",
    "                rtn = self.dataRV.rvcurve(name)\n",
    "                nameLoc = '{0}/vst{1}.csv'.format(rvDownloadLocation,name)\n",
    "                temp_df = pd.read_csv(nameLoc)\n",
    "                if not temp_df.empty:\n",
    "                    rv_temp = abs(temp_df['RV'])\n",
    "                    row = temp_df[temp_df['RV'] == rv_temp.max()]\n",
    "                    if row.empty: #The absolute max rv is negative \n",
    "                        row = temp_df[temp_df['RV'] == -rv_temp.max()]\n",
    "                    hiresName_fileName_rv_dic[\"RV\"] += [row[\"RV\"].to_numpy()[0]]\n",
    "                    hiresName_fileName_rv_dic[\"FILENAME\"] += [row[\"FILENAME\"].to_numpy()[0]]\n",
    "                else:\n",
    "                    #This is for removing these RV-less stars \n",
    "                    hiresName_fileName_rv_dic[\"RV\"] += [pd.NA]\n",
    "                    hiresName_fileName_rv_dic[\"FILENAME\"] += [pd.NA]\n",
    "            except OSError: #This error occurs because for some reason the star's rvcurve wasn't created\n",
    "                    #This is for removing these stars that have no RV metadata  \n",
    "                    hiresName_fileName_rv_dic[\"RV\"] += [pd.NA]\n",
    "                    hiresName_fileName_rv_dic[\"FILENAME\"] += [pd.NA]\n",
    "        df = pd.DataFrame(hiresName_fileName_rv_dic) \n",
    "        self.filename_rv_df = df.dropna() #If you don't drop the na's then other methods will break\n",
    "        self.filename_rv_df.to_csv(\"HIRES_Filename_rv.csv\",index_label=False,index=False)\n",
    "        print(\"Downloading RV Data Has Ended\")\n",
    "        \n",
    "\n",
    "    def DownloadSpectra(self):\n",
    "        '''\n",
    "        Description: This method downloads all the deblazed spectra from HIRES that are in\n",
    "                     self.filename_rv_df[\"FILENAME\"] to self.dataSpectra.localdir\n",
    "        '''\n",
    "        print(\"Downloading Spectra Has Began\")\n",
    "        self.spectraDic = {} \n",
    "        download_Location = self.dataSpectra.localdir #This is the second parameter of hiresprv.download.Download\n",
    "        for filename in self.filename_rv_df[\"FILENAME\"]:\n",
    "            #I tried to use the , seperation and new line seperation \n",
    "            #for the different file names but it doesn't seem to work.\n",
    "            #Thus, a for-loop was used!\n",
    "            self.dataSpectra.spectrum(filename.replace(\"r\",\"\"))  #Download spectra \n",
    "            file_path = \"{0}/{1}.fits\".format(download_Location,filename)\n",
    "            temp_deblazedFlux = fits.getdata(file_path)\n",
    "            temp_deblazedFlux = temp_deblazedFlux.flatten()\n",
    "            #spectraDic is the deblazed spectra \n",
    "            if not np.isnan(temp_deblazedFlux).any(): #Happens in the ivar\n",
    "                self.spectraDic[filename] = temp_deblazedFlux\n",
    "                self.SigmaCalculation(filename) #To get the sigma for Inverse variance \n",
    "            else:\n",
    "                print(f\"****{filename} HAS BEEN REMOVED BECAUSE IT CONTAINS NAN VALUES\")   \n",
    "        print(\"Downloading Spectra Has Ended\")\n",
    "\n",
    "    def ContinuumNormalize(self):\n",
    "        '''        \n",
    "        Description: This method uses specutils' Spectrum1D function to fit a function\n",
    "                     to each echelle order spectra then subtracts the function from the \n",
    "                     echelle order. \n",
    "                     The normalized spectra are put in the {} called self.spectraDic with\n",
    "                     the keys being the HIRES filename and the values being a continuum \n",
    "                     normalized 1-D array.   \n",
    "        '''\n",
    "        #This is the same for all HIRES data \n",
    "        print(\"Continuum Normalization Began\")\n",
    "    \n",
    "        spectral_axis_wl_solution = self.wl_solution*u.um\n",
    "        length = len(spectral_axis_wl_solution)\n",
    "        download_Location = self.dataSpectra.localdir \n",
    "        #Continumm Normalize\n",
    "        for filename in self.spectraDic:\n",
    "            deblazedFlux = self.spectraDic[filename]*u.Jy\n",
    "            ivarSigma = self.Ivar[filename]*u.Jy\n",
    "            normalized_array = np.array([])\n",
    "            ivar_array = np.array([])\n",
    "            \n",
    "            for j in range(0,16): #Normalize each individual echelle order \n",
    "                i  = 4021 * j #Each HIRES echelle order has 4021 elements \n",
    "                temp_echelle_wl,temp_echelle_flux = spectral_axis_wl_solution[i:i+4021],deblazedFlux[i:i+4021]\n",
    "                temp_sigma  =  ivarSigma[i:i+4021]\n",
    "                \n",
    "                #Use specutils' Spectrum1D to fit continuum normalize the echelle order\n",
    "                #referencing https://specutils.readthedocs.io/en/stable/spectrum1d.html\n",
    "                spectrum = Spectrum1D(flux=temp_echelle_flux, spectral_axis=temp_echelle_wl)\n",
    "                g1_fit = fit_generic_continuum(spectrum)\n",
    "                flux_fit = g1_fit(temp_echelle_wl)\n",
    "                \n",
    "                #Subracting the continuum from the echelle order & \n",
    "                #the section of sigma corresponding to the current echelle order\n",
    "                normalized_echelle = temp_echelle_flux / flux_fit\n",
    "                normalized_ivar = temp_sigma / flux_fit\n",
    "                #Converting to a float like this removes 2 decimal places from normalized_echelle\n",
    "                normalized_echelle = np.array(list(map(np.float,normalized_echelle))) \n",
    "                normalized_ivar = np.array(list(map(np.float,normalized_ivar))) \n",
    "                #Make all the echelle spectra into a 1-D array again\n",
    "                normalized_array = np.append(normalized_array,normalized_echelle)\n",
    "                ivar_array = np.append(ivar_array,normalized_ivar)\n",
    "            spec_norm_scaled = normalized_array/np.repeat(np.percentile(normalized_array, 95, axis=0)[np.newaxis], length, axis=0)\n",
    "            self.spectraDic[filename] = spec_norm_scaled #1D normalized spectra (all 16 echelle orders)\n",
    "            self.Ivar[filename] = ivar_array #Technically this isn't the inverse variacne yet\n",
    "        print(\"Continuum Normalization Ended\")\n",
    "            \n",
    "    def CrossCorrelate(self,numOfEdgesToSkip = 100):\n",
    "        '''\n",
    "        Description: Uses Pyastronomy's crosscorrRV function to compute the cross correlation.\n",
    "\n",
    "                     The updated spectra are put into self.spectraDic.   \n",
    "\n",
    "        numOfEdgesToSkip: the amount of pixels to cut off both ends of the spectra.\n",
    "        '''\n",
    "        print(\"Cross Correlate Has Began\")\n",
    "        wl_solution = np.genfromtxt('./wl_solution.csv',skip_header=2) #UNITS: Angstrom\n",
    "        solar = np.load('../Constants/solarAtlas.npy')\n",
    "        wvlen = solar[:,1][::-1]\n",
    "        c = solar[:,4][::-1]\n",
    "        \n",
    "        solar_echelle_list = []\n",
    "        for echelle_num in range(16):\n",
    "            begin,end = 4021*echelle_num, 4021*(echelle_num+1)\n",
    "            temp_echelle_wv = wl_solution[begin:end]\n",
    "            temp_lower_bound = wvlen >= temp_echelle_wv[0]\n",
    "            temp_upper_bound = wvlen[temp_lower_bound] <= temp_echelle_wv[-1]\n",
    "            temp_wv = wvlen[temp_lower_bound][temp_upper_bound]\n",
    "            temp_c = c[temp_lower_bound][temp_upper_bound]\n",
    "            solar_echelle_list.append((temp_wv,temp_c))\n",
    "        \n",
    "        \n",
    "        wl_solution = np.genfromtxt('./wl_solution.csv',skip_header=2) #UNITS: Angstrom\n",
    "        RV = 80 #60 gave good results \n",
    "        crossCorrelatedspectra = {} #Key: FILENAME Values: (correlated wavelength, normalized flux)\n",
    "        for i in range(self.filename_rv_df.shape[0]):\n",
    "            try:\n",
    "                row = self.filename_rv_df.iloc[i]\n",
    "                filename = row[1]\n",
    "                normalizedFlux = self.spectraDic[filename]\n",
    "\n",
    "                z_list = [] #Going to take the average of all the echelle shifts \n",
    "                for echelle_num in range(15,16): #echelle orders\n",
    "    #             for echelle_num in range(16):\n",
    "                    begin,end = 4021*echelle_num, 4021*(echelle_num+1)\n",
    "                    e_wv = wl_solution[begin:end]  #hires \n",
    "                    e_flux = normalizedFlux[begin:end]\n",
    "                    s_wv = solar_echelle_list[echelle_num][0]    #solar     \n",
    "                    s_flux = solar_echelle_list[echelle_num][1]  \n",
    "\n",
    "                    rv, cc = pyasl.crosscorrRV(e_wv, e_flux,s_wv,s_flux, -1*RV, RV, RV/200., skipedge=numOfEdgesToSkip)\n",
    "                    argRV = rv[np.argmax(cc)]  #UNITS: km/s \n",
    "                    z = (argRV/299_792.458) #UNITS: None \n",
    "                    z_list.append(z)\n",
    "\n",
    "                avg_z = np.mean(z_list)    \n",
    "                computeShiftedWavelength = lambda wl: wl/ (1 + avg_z)  #UNITS: Angstroms\n",
    "                #There has to be a better way to convert to a numpy array\n",
    "                shifted_wl = np.array(list(map(computeShiftedWavelength,wl_solution)))\n",
    "                self.spectraDic[filename] = (shifted_wl,normalizedFlux)    \n",
    "            except:\n",
    "                pass \n",
    "        print(\"Cross Correlate Has Ended\")\n",
    "        \n",
    "\n",
    "    def Interpolate(self):\n",
    "        '''        \n",
    "        Description: This method downloads the interpolated wavelength to interpolated_wl.csv \n",
    "                     and downloads the fluxes to fluxes_for_HIRES.csv. \n",
    "        '''\n",
    "        print(\"Interpolation Has Began\")\n",
    "        #Interpolate the spectra with each other to get the same wavelength scale for all of them.\n",
    "        maxMinVal = float('-inf')  \n",
    "        minMaxVal = float('inf')\n",
    "        #Finds the max minimum wavelength val & finds the min maximum wavelenght val \n",
    "        for spectra_flux_tuple in self.spectraDic.values(): \n",
    "            #Assumption: wavelength is sorted from the 0th index being min,\n",
    "            #            the len(wavelength array)-1 is the max wavelength val,\n",
    "            #            all the wavelength arrays are the same length.\n",
    "            temp_spectra = spectra_flux_tuple[0]\n",
    "            temp_min_wl = temp_spectra[0]\n",
    "            temp_max_wl = temp_spectra[-1]\n",
    "            \n",
    "            if maxMinVal < temp_min_wl:\n",
    "                maxMinVal = temp_min_wl\n",
    "            if minMaxVal > temp_max_wl:\n",
    "                minMaxVal = temp_max_wl\n",
    "        \n",
    "        #Wavelength range \n",
    "        firstKey = next(iter(self.spectraDic))\n",
    "        first_spectra = self.spectraDic[firstKey][0]\n",
    "        interpolate_over = [wl for wl in first_spectra if wl >= maxMinVal and wl<= minMaxVal]   \n",
    "        length_interpolate = len(interpolate_over)\n",
    "        \n",
    "        spoc_wl = np.genfromtxt(\"../spocData/wavelengths_flat.txt\")\n",
    "        \n",
    "        spoc_wl = spoc_wl[spoc_wl >= interpolate_over[0]]\n",
    "        spoc_wl = spoc_wl[spoc_wl <= interpolate_over[-1]]\n",
    "        \n",
    "        interpolate_over = spoc_wl[::-1]\n",
    "        interpolate_over.sort()\n",
    "        \n",
    "        length_interpolate = len(interpolate_over)\n",
    "        \n",
    "        #Interpolation         \n",
    "        replacementSpectraDic = {}\n",
    "        replacementIvarDic = {}\n",
    "        \n",
    "        for HIRESname,filename,rv in self.filename_rv_df.to_numpy():\n",
    "            try:\n",
    "                wl = self.spectraDic[filename][0]\n",
    "                flux_norm = self.spectraDic[filename][1]\n",
    "                flux_func = interpolate.interp1d(wl, flux_norm)\n",
    "                ivar_func = interpolate.interp1d(wl,self.Ivar[filename])\n",
    "\n",
    "                replacementSpectraDic[HIRESname] = flux_func(interpolate_over)\n",
    "                #Now ivar will actually become ivar \n",
    "                replacementIvarDic[HIRESname] = 1/ivar_func(interpolate_over)**2 \n",
    "            except:\n",
    "                pass\n",
    "        if np.isnan(replacementIvarDic[HIRESname]).any(): #Happens in the ivar\n",
    "                print(f\"****{HIRESname} HAS BEEN REMOVED BECAUSE IT CONTAINS NAN VALUES\")\n",
    "                del replacementSpectraDic[HIRESname]\n",
    "                del replacementIvarDic[HIRESname]\n",
    "            \n",
    "            \n",
    "        self.spectraDic = replacementSpectraDic\n",
    "        self.Ivar = replacementIvarDic\n",
    "        self.interpolation_range = interpolate_over\n",
    "        \n",
    "        \n",
    "        #Saving Data\n",
    "        np.savetxt(\"interpolated_wl.csv\",interpolate_over,delimiter=\",\",header='wavelength(Angstrom)')\n",
    "        fluxDF = pd.DataFrame(self.spectraDic)\n",
    "        np.save(\"stellar_names_for_flux_and_ivar\",np.array(fluxes_for_HIRES.columns))\n",
    "        np.save(\"fluxes_for_HIRES\",fluxDF.to_numpy())\n",
    "        ivarDF = pd.DataFrame(self.Ivar)\n",
    "        np.save(\"ivars_for_HIRES\",ivarDF.to_numpy())\n",
    "\n",
    "        #This might be confusing to now make self.Ivar a dataframe when it was \n",
    "        #just a dictionary, but thats okay. Don't want to make too many variables.\n",
    "        self.Ivar = ivarDF     \n",
    "        self.fluxDF  = fluxDF\n",
    "        self.interpolate_wl = interpolate_over\n",
    "        print(\"Interpolation Has Ended\")\n",
    "\n",
    "    def SigmaCalculation(self,star_name):\n",
    "        '''\n",
    "        Description: Calculates sigma for inverse variance (ivar) \n",
    "        '''\n",
    "        gain = 1.2 #electrons/ADU\n",
    "        readn = 2.0 #electrons RMS\n",
    "        xwid = 5.0 #pixels, extraction width\n",
    "\n",
    "        sigma = np.sqrt((gain*self.spectraDic[star_name]) + (xwid*readn**2))/gain \n",
    "        #Checkinng for a division by zeros \n",
    "        if not np.isnan(sigma).any(): #Happens in the ivar\n",
    "                self.Ivar[star_name] = sigma\n",
    "        else:\n",
    "            print(f\"****{star_name} HAS BEEN REMOVED BECAUSE IT CONTAINS NAN VALUES\") \n",
    "            del self.spectraDic[star_name]\n",
    "        \n",
    "    \n",
    "    def AlphaNormalization(self):\n",
    "        '''\n",
    "        Description: Rolling Continuum Normalization. Takes forever and it mega worth it. \n",
    "        '''\n",
    "        print(\"Alpha Normalization has Begun\")\n",
    "        wl_sixteen_echelle = np.ones((16,4021))\n",
    "        for row in range(16):\n",
    "            begin,end = 4021*row, 4021*(row+1)\n",
    "            wl_sixteen_echelle[row] = self.wl_solution[begin:end]\n",
    "        i = 0 #DELETE WHEN DONE  \n",
    "        for star_name in self.spectraDic:\n",
    "            try: #This is so the program doesn't have to redo the same stars over and over again\n",
    "                normed_spectra = np.load(f\"Normalized_Spectra/{star_name}_specnorm.npy\").flatten()\n",
    "                self.spectraDic[star_name] = normed_spectra\n",
    "                self.Ivar[star_name] = np.load(f\"Normalized_Spectra/{star_name}_sigmanorm.npy\").flatten()\n",
    "            except:\n",
    "                temp_sixteen_order_echelle = np.ones((16,4021))\n",
    "                temp_sixteen_order_echelle_sigma = np.ones((16,4021))\n",
    "                temp_spectra = self.spectraDic[star_name]\n",
    "                temp_sigma = self.Ivar[star_name]\n",
    "                for row in range(16):\n",
    "                    begin,end = 4021*row, 4021*(row+1)\n",
    "                    temp_sixteen_order_echelle[row] = temp_spectra[begin:end]\n",
    "                    temp_sixteen_order_echelle_sigma[row] = temp_sigma[begin:end]\n",
    "                contfit_alpha_hull(star_name,\n",
    "                                   temp_sixteen_order_echelle,\n",
    "                                   temp_sixteen_order_echelle_sigma,\n",
    "                                   wl_sixteen_echelle,\"./Normalized_Spectra/\")\n",
    "                try:\n",
    "                    #Should change ./Normalized_Spectra/ to be where the user can set it but that is okay :D \n",
    "                    #**FIX THIS FOR FINAL DRAFT \n",
    "                    self.spectraDic[star_name] = np.load(f\"Normalized_Spectra/{star_name}_specnorm.npy\").flatten()\n",
    "                    self.Ivar[star_name] = np.load(f\"Normalized_Spectra/{star_name}_sigmanorm.npy\").flatten()\n",
    "                except:\n",
    "                    print(f'''Something with wrong with {star_name}'s normalization.\n",
    "                             We have removed it...''')\n",
    "                    del self.spectraDic[star_name]\n",
    "                    del self.Ivar[star_name]\n",
    "        print(\"Alpha Normalization has Begun\")\n",
    "         \n",
    "\n",
    "    def NoDownload(self):\n",
    "        '''\n",
    "        Description: Need to have spectra already downloaded and HIRES_Filename_rv.csv needs to be made already.\n",
    "        Only made this method because the internet at my parents house is extremely poor. 1.1 mbs \n",
    "        '''\n",
    "        hires,file = np.genfromtxt(\"HIRES_Filename_rv.csv\",delimiter=',',usecols=(0,1),skip_header=1,dtype='str',unpack = True)\n",
    "        rv = np.genfromtxt(\"HIRES_Filename_rv.csv\",delimiter=',',usecols=(2),skip_header=1)\n",
    "        self.filename_rv_df = pd.DataFrame({\"HIRESName\":hires,'FILENAME':file,\"RV\":rv})\n",
    "        download_Location = self.dataSpectra.localdir #This is the second parameter of hiresprv.download.Download\n",
    "        self.spectraDic = {}\n",
    "        for filename in self.filename_rv_df[\"FILENAME\"]:\n",
    "            #I tried to use the , seperation and new line seperation \n",
    "            #for the different file names but it doesn't seem to work.\n",
    "            #Thus, a for-loop was used!\n",
    "            #self.dataSpectra.spectrum(filename.replace(\"r\",\"\"))  #Download spectra \n",
    "            file_path = \"{0}/{1}.fits\".format(download_Location,filename)\n",
    "            try:\n",
    "                temp_deblazedFlux = fits.getdata(file_path).flatten()\n",
    "                self.spectraDic[filename] = temp_deblazedFlux\n",
    "                self.SigmaCalculation(filename)\n",
    "            except OSError: #More of a problem with fits but that is okay\n",
    "                print(f\"{filename} has a problem with it's spectra\")\n",
    "        print(\"Completed Getting The dAtA\")             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOA userid: \n",
      "KOA Password: ········\n",
      "Failed to login: Required input 'userid' not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-0a22ea3afbf6>:330: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma = np.sqrt((gain*self.spectraDic[star_name]) + (xwid*readn**2))/gain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****r20120306.119 HAS BEEN REMOVED BECAUSE IT CONTAINS NAN VALUES\n",
      "r20150208.120 has a problem with it's spectra\n",
      "****r20120306.113 HAS BEEN REMOVED BECAUSE IT CONTAINS NAN VALUES\n",
      "Completed Getting The dAtA\n",
      "Alpha Normalization has Begun\n",
      "Alpha Normalization has Begun\n",
      "Cross Correlate Has Began\n",
      "Cross Correlate Has Ended\n",
      "Interpolation Has Began\n",
      "Interpolation Has Ended\n",
      "This took 15.291445855299632 minutes!\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    crossMatchedNames = pd.read_csv(\"../spocData/starnames_crossmatch_SPOCS_NEXSCI.txt\",sep=\" \")\n",
    "    cirObject = CIR(crossMatchedNames[\"HIRES\"].to_numpy(),'./wl_solution.csv','./RVOutput','./SpectraOutput')\n",
    "    cirObject.Run(True,True)\n",
    "    time_elap = time.time() - start_time \n",
    "    print(f\"This took {time_elap/60} minutes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
